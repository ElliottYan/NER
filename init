import numpy as np
import os
import pdb


def init():
    fix_len = 60
    vec, word_id = read_in_word2vec()
    relation_id = read_in_relations()
    train_mention = read_in(word_id, relation_id, fix_len, train_test="train")
    test_mention = read_in(word_id, relation_id, fix_len, train_test="test")


def pos_embed(x, lower, upper, fix_len):
    return max(lower, min(x + fix_len, upper))


def read_in_word2vec():
    print("Now reading Word_embeddings!")
    vec = []
    word_id = {}
    f = open(os.getcwd()+"/origin_data/vec.txt")
    f.readline()
    count = 0
    while True:
        content = f.readline()
        if content == "" :
            break
        content = content.strip().split()
        word_id[content[0]] = count
        count += 1
        content = [float(c) for c in content[1:]]
        vec.append(content)
    f.close()
    dim = 50
    word_id["BLANK"] = len(word_id)
    vec.append(np.random.normal(size=dim, loc=0, scale=0.05))
    word_id["UNK"] = len(word_id)
    vec.append(np.random.normal(size=dim, loc=0, scale=0.05))
    vec = np.array(vec, dtype = np.float32)
    # pdb.set_trace()
    return (vec,word_id)
#   there were two random vectors which i think is unecessary.


def read_in_relations():
    print('Now reading in Relationship ids!')
    relation_id = {}
    f = open(os.getcwd() + "/origin_data/relation2id.txt")
    while True:
        content = f.readline()
        if content == "":
            break
        content = content.strip().split()
        relation_id[content[0]] = int(content[1])
    return relation_id


def read_in_data(func):
    def call(*args, train_test="train"):
        if train_test == "train":
            f = open(os.getcwd() + "/origin_data/train.txt")
        elif train_test == "test":
            f = open(os.getcwd() + "/origin_data/test.txt")
        else:
            print("Wrong argument in calling read_in functions!")
            return
        print("Now is time for reading the " + train_test + " data!")
        return func(*args, f)
    return call

@read_in_data
def read_in(word_id, relation_id, fix_len, f):
    mentions = {}
    n_relation = len(relation_id)
    while True:
        content = f.readline()
        if content == "":
            break
        content = content.strip().split()
        # in this case, the entity pair comes in with same order
        en1 = content[2]
        en2 = content[3]
        tup = (en1, en2)
        relation = 0
        if content[4] not in relation_id:
            relation = relation_id["NA"]
        else:
            relation = relation_id[content[4]]

        # every tuple is a mentions-bag level object

        # Data Structure
        #   mentions :(tuple) -> labels -> embeddings
        #   label is one-hot

        # construct mentions-bag if not exist

        # label = [0] * n_relation
        # label[relation] = 1

        # if no such tuple appeared
        if tup not in mentions:
            mentions[tup] = {}

        # if no such relation appeared
        if relation not in mentions[tup].keys():
            mentions[tup][relation] = []

        sentence = content[5:-1]
        try:
            en1pos = sentence.index(en1)
            pass1 = True
            en2pos = sentence.index(en2)
        except:
            # still need to solve this problem
            # en1 , en2 format may not be like its mentions in sentence
            if pass1 == True:
                en2pos = 0
            else:
                en1pos = 0
        # construct the mentions in each bag
        # with [word, en1pos, en2pos]
        output = []
        for i in range(min(fix_len, len(sentence))):
            en1pos = pos_embed(i - en1pos, 0, fix_len * 2, fix_len)
            en2pos = pos_embed(i - en2pos, 0, fix_len * 2, fix_len)
            word = sentence[i]
            if word not in word_id:
                word = "UNK"
            word = word_id[word]
            output.append([word, en1pos, en2pos])

        mentions[tup][relation].append(output)

    return mentions









init()
